{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use python 3.8.10 to run this notebook !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install following packages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm==4.61.2\n",
    "# !pip install numpy==1.20.3\n",
    "# !pip install scikit-learn==0.24.2\n",
    "# !pip install pandas==1.4.1\n",
    "# !pip install umap-learn==0.4.6\n",
    "# !pip install anndata==0.7.4\n",
    "# !pip install ripser==0.6.1\n",
    "# !pip install Cython==0.29.21\n",
    "# !pip install numba==0.51.2\n",
    "# !pip install seaborn\n",
    "# !pip install tables==3.6.1\n",
    "# !pip install legacy-api-wrap==1.2\n",
    "# !pip install scikit-network==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from anndata import AnnData\n",
    "import scanpy_modified as scanpy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "from ripser import Rips\n",
    "from scipy.spatial import distance\n",
    "from numpy import linalg as LA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import glob, os\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import features_dpt_entropy, features_homology_dpt_entropy, features_vector\n",
    "from utils import features_ripley_dpt_v2, preprocessing, features_avg_connection_dpt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sknetwork.data import karate_club, painters, movie_actor\n",
    "from sknetwork.clustering import Louvain, modularity, bimodularity\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "import simdata_generator as dataset\n",
    "\n",
    "eps = sys.float_info.epsilon\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Simulated Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datasets for each type of simulated dataset\n",
    "repeat = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3000/3000 [00:00<00:00, 6734.25it/s]\n",
      "100%|████████████████████████████████████| 3000/3000 [00:00<00:00, 12860.14it/s]\n"
     ]
    }
   ],
   "source": [
    "df_cluster = []\n",
    "for i in tqdm(range(repeat),position=0, leave=True):\n",
    "    sim = dataset.gen_cluster(num=np.random.randint(500,1500))\n",
    "    df_cluster.append(sim)\n",
    "\n",
    "df_traj = []\n",
    "for i in tqdm(range(repeat),position=0, leave=True):\n",
    "    sim = dataset.gen_trajectory(num=np.random.randint(500,1500))\n",
    "    df_traj.append(sim)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3000/3000 [00:00<00:00, 5871.43it/s]\n",
      "100%|█████████████████████████████████████| 3000/3000 [00:00<00:00, 7658.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df_rand_cluster = []\n",
    "for i in tqdm(range(repeat),position=0, leave=True):\n",
    "    sim, ind = dataset.gen_random(num=np.random.randint(500,1500),mode='cluster')\n",
    "    df_rand_cluster.append(sim)\n",
    "\n",
    "df_rand_traj = []\n",
    "for i in tqdm(range(repeat),position=0, leave=True):\n",
    "    sim, ind = dataset.gen_random(num=np.random.randint(500,1500),mode='trajectory')\n",
    "    df_rand_traj.append(sim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = df_cluster + df_rand + df_rand_cluster + df_rand_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 18000/18000 [05:34<00:00, 53.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# if you want to save scatter plots of each dataset, run this cell! \n",
    "ct=0\n",
    "for a in tqdm(all_df):\n",
    "    ct += 1\n",
    "    fig = plt.figure(figsize=(1.5,1.5))\n",
    "    plt.scatter(a[:,0],a[:,1],s=1)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    fig.patch.set_edgecolor('black')  \n",
    "    fig.patch.set_linewidth('1') \n",
    "    plt.axis('off')\n",
    "    fig.savefig('scatterplots/{}.png'.format(ct))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9000/9000 [33:25:16<00:00, 13.37s/it]\n"
     ]
    }
   ],
   "source": [
    "# generation of scores\n",
    "META_SCORES = []\n",
    "ct = 0\n",
    "for df in tqdm(all_df, position=0, leave=True):\n",
    "    df = preprocessing(df)\n",
    "    sc1 = features_dpt_entropy(df, num_bins = 10)\n",
    "    sc2 = features_homology_dpt_entropy(df,num_bins = 3)\n",
    "    sc3 = features_vector(df)\n",
    "    sc4 = features_ripley_dpt_v2(df)\n",
    "    sc5 = features_avg_connection_dpt(df)\n",
    "    scores = [sc1,sc2,sc3,sc4,sc5]\n",
    "    \n",
    "    META_SCORES.append(scores)\n",
    "    if ct % 3000 == 0:\n",
    "        np.save('tmp_{}.npy'.format(ct), np.array(META_SCORES))\n",
    "    ct += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the meatascore\n",
    "np.save('metascore_12000.npy', np.array(META_SCORES))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
